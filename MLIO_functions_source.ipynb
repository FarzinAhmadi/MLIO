{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.linewidth'] = 3\n",
    "#input csv files of all data\n",
    "total_nut_day_1_df = pd.read_csv(\"Input_data/DR1TOT.csv\") #, dtype = np.float64) #convert_float = True)\n",
    "total_nut_day_1_df = total_nut_day_1_df.replace(\" \", \"-1000\")\n",
    "total_nut_day_2_df = pd.read_csv(\"Input_data/DR2TOT.csv\")\n",
    "total_nut_day_2_df = total_nut_day_2_df.replace(\" \", \"-1000\")\n",
    "ind_food_1_df = pd.read_csv(\"Input_data/DR1IFF_I.csv\")\n",
    "ind_food_2_df = pd.read_csv(\"Input_data/DR2IFF.csv\")\n",
    "demo_df = pd.read_csv(\"Input_data/Demographics.csv\")\n",
    "A_Data= pd.read_csv (\"Input_data/A_based_on_data.csv\")\n",
    "b_Data= pd.read_csv (\"Input_data/b_MLIO.csv\")\n",
    "#A_general_reduced = pd.read_csv (\"A-matrix-General.csv\")\n",
    "#A_general = pd.read_csv (\"A-matrix-General - All foods.csv\")\n",
    "#nitrient_bounds_df = pd.read_csv (\"Nutrient_bounds.csv\")\n",
    "total_nut_day_1_df = total_nut_day_1_df.astype(float)\n",
    "total_nut_day_2_df = total_nut_day_2_df.astype(float)\n",
    "total_nut_day_1_df_mod = total_nut_day_1_df[(total_nut_day_1_df.DR1TSODI <= 3000)]\n",
    "total_nut_day_2_df_mod = total_nut_day_2_df[(total_nut_day_2_df.DR2TSODI <= 3000)  ]\n",
    "df_temp = total_nut_day_2_df_mod[total_nut_day_2_df_mod.SEQN.isin(total_nut_day_1_df_mod.SEQN)]\n",
    "ind_food_1_df_mod = ind_food_1_df#[ind_food_1_df.SEQN.isin(df_temp.SEQN)]\n",
    "ind_food_1_df_mod.DR1IFDCD = np.floor(ind_food_1_df_mod.DR1IFDCD/1000000).astype(int)\n",
    "ind_food_2_df_mod = ind_food_2_df#[ind_food_2_df.SEQN.isin(df_temp.SEQN)]\n",
    "ind_food_2_df_mod.DR2IFDCD = np.floor(ind_food_2_df_mod.DR2IFDCD/1000000).astype(int)\n",
    "#ind_food_1_df_mod.DR1IFDCD\n",
    "#ind_food_2_df_mod.DR2IFDCD\n",
    "demo_df_mod = demo_df[demo_df.SEQN.isin(df_temp.SEQN)]\n",
    "demo_df_mod_male = demo_df_mod[demo_df_mod.RIAGENDR == 1]\n",
    "demo_df_mod_female = demo_df_mod[demo_df_mod.RIAGENDR == 2]\n",
    "#Age divide\n",
    "demo_all = demo_df_mod [(demo_df_mod.RIDAGEYR >= 18) & (demo_df_mod.RIDAGEYR <= 75)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coloured_clusters(X,centroids,count):\n",
    "    h = .01    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    x_min, x_max = 1, 10\n",
    "    y_min, y_max = 1, 10\n",
    "#    x_min, x_max = X.T[:, 0].min() -.5, X.T[:, 0].max() +.5\n",
    "#    y_min, y_max = X.T[:, 1].min() -.5, X.T[:, 1].max() +.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    xx1 = xx.reshape((xx.shape[0]*xx.shape[0],1))\n",
    "    yy1 = yy.reshape((yy.shape[0]*yy.shape[0],1))\n",
    "    xxyy1 = np.concatenate((xx1, yy1), axis=1)\n",
    "    #xxyy_centroid = find_cluster(xxyy1.T, data)\n",
    "    xxyy_centroid = find_cluster_from_centroid(xxyy1.T, centroids)\n",
    "    P = xxyy_centroid[2].reshape(xx.shape)\n",
    "    plt.figure(figsize=(7,7))#; subplot(111,aspect='equal')\n",
    "    plt.clf()\n",
    "    plt.imshow(P, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.Paired,\n",
    "           aspect='equal', origin='lower', alpha=0.1)\n",
    "    #plt.scatter(X[:, 0], X[:, 1], c='k', alpha=0.5)\n",
    "    plt.xlim([0, 11])\n",
    "    plt.ylim([0, 11])\n",
    "    plt.xlabel(u'x\\u2081')\n",
    "    plt.ylabel(u'x\\u2082')\n",
    "    plt.plot([1,1], [1, 10], c=\"black\")\n",
    "    plt.plot([10,10], [1, 5], c=\"black\")\n",
    "    plt.plot([1,5], [10, 10], c=\"black\")\n",
    "    plt.plot([1,10], [1, 1], c=\"black\")\n",
    "    plt.plot([10,5], [5, 10], c=\"black\")\n",
    "    #plt.fill_between([1,5], [10,10],[1,1], facecolor='black', alpha=0.15)\n",
    "    #plt.fill_between([5,10], [10,5],[1,1], facecolor='black', alpha=0.15)\n",
    "    centroids = centroids\n",
    "    #plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "    #             marker='s', s=169, linewidths=3,\n",
    "    #            color='black',\n",
    "    #            zorder=10, alpha=1)\n",
    "    # Shade the area between y1 and y2\n",
    "    x =  [5,10]\n",
    "    y1 = [10,5]\n",
    "    y2 = [10,10]\n",
    "    #plt.grid()\n",
    "    plt.fill_between(x, y1, y2,\n",
    "                         facecolor=\"orange\", # The fill color\n",
    "                         color='white',       # The outline color\n",
    "                        alpha=1)          # Transparency of the fill\n",
    "    if True:\n",
    "        X_centroids = find_cluster_from_centroid(X, centroids)\n",
    "        plt.gca().set_prop_cycle(None)\n",
    "        for j in np.unique(X_centroids[2,:]):\n",
    "            indices = [i for i in range(X_centroids.shape[1]) if X_centroids[2,i] == j]\n",
    "            plt.scatter(X.T[indices, 0], X.T[indices, 1], alpha=0.5)\n",
    "        plt.gca().set_prop_cycle(None)   \n",
    "        for j in np.unique(X_centroids[2,:]):\n",
    "            plt.scatter(centroids[int(j), 0], centroids[int(j), 1], marker='s', s=169, linewidths=3)\n",
    "    if False:\n",
    "        plt.scatter(X.T[:, 0], X.T[:, 1], \n",
    "                    c= 'k'\n",
    "                    , alpha=0.3)    \n",
    "        # Show the plot\n",
    "    #plt.savefig('Saved_figures/2D example/2Dfigure'+str(count)+'.png', dpi=100)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster_from_centroid(X, X_train):\n",
    "    dist_min = -1\n",
    "    m = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    X_test = np.zeros ([m+1,k])\n",
    "    X_test[0:m]= X\n",
    "    X_testT = X_test.T\n",
    "    X_trainT = X_train.T\n",
    "    temp = np.array([])\n",
    "    iteration = 0\n",
    "    for i in range(X_testT.shape[0]):\n",
    "        iteration = 0\n",
    "        dist_min = -1\n",
    "        dist = 0\n",
    "        count = 0\n",
    "        for n in range(X_train.shape[0]):\n",
    "            dist += np.linalg.norm(X_testT[i,0:m] - X_train[n,0:m]) \n",
    "            #dist += sum (abs (X_testT[i,0:m] - X_train[n,0:m]))\n",
    "            count += 1\n",
    "            if iteration == 0: \n",
    "                dist_min = dist\n",
    "                iteration +=1\n",
    "                X_test[m,i] = n\n",
    "            elif dist < dist_min: \n",
    "                dist_min = dist\n",
    "                X_test[m,i] = n\n",
    "            dist = 0\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_for_comparison(A,b,X, max_number_of_clusters,figure):\n",
    "    m = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    X_train = np.zeros ([m+1,k])\n",
    "    X_train[0:m]= X\n",
    "    XT = X.T        \n",
    "    #max_number_of_clusters = 8\n",
    "    dif =                   np.zeros (max_number_of_clusters)\n",
    "    dif_train =             np.zeros (max_number_of_clusters)\n",
    "    dif_test =              np.zeros (max_number_of_clusters)\n",
    "    opt_gap =               np.zeros (max_number_of_clusters)\n",
    "    dif_train_cluster_avg = np.zeros (max_number_of_clusters)\n",
    "    dif_train_cluster_avg_1 = np.zeros (max_number_of_clusters)\n",
    "    dif_train_cluster_avg_2 = np.zeros (max_number_of_clusters)\n",
    "    IO_points_dic = {}\n",
    "    #sodium_ML = np.zeros ([max_number_of_clusters, max_number_of_clusters,nutrient_names.shape[0]])\n",
    "    #sodium_disjoint = np.zeros ([max_number_of_clusters, max_number_of_clusters,nutrient_names.shape[0]])\n",
    "    count = 0  \n",
    "    for n in range(max_number_of_clusters):\n",
    "        IO_points_dic[str(n+1)+'_cluster_centers'] = {}\n",
    "        kmeans = KMeans(n_clusters=n + 1, random_state=0).fit(XT)\n",
    "        #print (np.unique(kmeans.labels_))\n",
    "        X_train[m]= kmeans.labels_\n",
    "        IO_points = kmeans.cluster_centers_\n",
    "        if (X.shape[0] ==2):\n",
    "            plot_coloured_clusters(X,IO_points,count)\n",
    "        count += 1 \n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLIO_MIQCP(A,b,X,num_clusters):\n",
    "    m1 = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    K = X.shape[0]\n",
    "    L = num_clusters\n",
    "    AT = A.T\n",
    "    num_var = 2 * K * n + 3 * n + m1\n",
    "    m = gp.Model(\"MLIO_MIQCP\")\n",
    "    m.Params.timeLimit = 100.0\n",
    "    #m.Params.OutputFlag = 0\n",
    "    # Create variables\n",
    "    e = m.addVars(K,n,  lb=-GRB.INFINITY, name = 'e')\n",
    "    t = m.addVars(K,n,  lb=-GRB.INFINITY, name = 't')\n",
    "    c = m.addVars(n,L,  lb=-GRB.INFINITY, name = 'c')\n",
    "    y = m.addVars(m1,L,  lb=-GRB.INFINITY, name = 'y')\n",
    "    d = m.addVars(n,  lb=-GRB.INFINITY, name = 'd')\n",
    "    z = m.addVars(n,L, name = 'z')\n",
    "    v = m.addVars(K,L, vtype=gp.GRB.BINARY)\n",
    "\n",
    "    # Set objective:\n",
    "    m.setObjective(gp.quicksum(t[k,i] for k in range (K) for i in range(n)), GRB.MINIMIZE)\n",
    "    # Constraints\n",
    "    \n",
    "    for k in range (K):\n",
    "        m.addConstrs(t[k,i] >= e[k,i] for i in range(n))\n",
    "        m.addConstrs(t[k,i] >= -e[k,i] for i in range(n))\n",
    "    for k in range (K):\n",
    "        for l in range (L):\n",
    "            m.addConstrs( (X[k,i] - e[k,i]) * v[k,l]  == z[i,l] * v[k,l] for i in range(n))\n",
    "    for j in range(m1):\n",
    "        for l in range (L):\n",
    "            m.addConstr(gp.quicksum(A[j,i] * z[i,l] for i in range(n)) <= b[j])\n",
    "    for i in range(n):\n",
    "        for l in range (L):\n",
    "            m.addConstr(gp.quicksum(y[j,l] * A[j,i] for j in range(m1)) == c[i,l])    \n",
    "    m.addConstrs(y[j,l] >= 0 for j in range(m1) for l in range (L) )\n",
    "    for l in range (L):\n",
    "        m.addConstr(gp.quicksum(c[j,l] * z[j,l] for j in range(n)) == gp.quicksum(b[i] * y[i,l] for i in range(m1)))\n",
    "    #for i in range(n):\n",
    "    #    m.addConstr(d[i] == gp.abs_(c[i]))\n",
    "    #m.addConstr(gp.quicksum(d[i] for i in range(n)) == 1)  \n",
    "    for l in range (L):\n",
    "        m.addConstr(gp.quicksum(y[j,l]  for j in range(m1)) == 1)\n",
    "    for k in range (K):\n",
    "        m.addConstr(gp.quicksum(v[k,l]  for l in range(L)) == 1)\n",
    "    m.params.NonConvex = 2   \n",
    "    m.optimize()\n",
    "    vars = m.getVars()\n",
    "    #for i in range (n):\n",
    "    #    print (vars [num_var -1 -(n-1-i)])\n",
    "#     n = A.shape[1]\n",
    "    Z = np.zeros (n*L)\n",
    "    C = np.zeros (n*L)\n",
    "    #Z = np.array([x.X for x in z.values()])\n",
    "    #C = np.array([x.X for x in c.values()])\n",
    "    count = 0\n",
    "    for v in z.values():\n",
    "        Z[count] = v.X\n",
    "        count += 1\n",
    "    count = 0\n",
    "    for v in c.values():\n",
    "        C[count] = v.X\n",
    "        count += 1\n",
    "    return Z, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MIQCP_for_2D_example(A,b,X, max_number_of_clusters,figure):\n",
    "    m = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    X_train = np.zeros ([m+1,k])\n",
    "    X_train[0:m]= X\n",
    "    XT = X.T       \n",
    "    #max_number_of_clusters = 8\n",
    "    dif =                   np.zeros (max_number_of_clusters)\n",
    "    dif_train =             np.zeros (max_number_of_clusters)\n",
    "    dif_test =              np.zeros (max_number_of_clusters)\n",
    "    opt_gap =               np.zeros (max_number_of_clusters)\n",
    "    dif_train_cluster_avg = np.zeros (max_number_of_clusters)\n",
    "    dif_train_cluster_avg_1 = np.zeros (max_number_of_clusters)\n",
    "    dif_train_cluster_avg_2 = np.zeros (max_number_of_clusters)\n",
    "    IO_points_dic = {}\n",
    "    count = 0  \n",
    "    for n in range(max_number_of_clusters):\n",
    "        IO_points_dic[str(n+1)+'_cluster_centers'] = {}\n",
    "        #kmeans = KMeans(n_clusters=n + 1, random_state=0).fit(XT)\n",
    "        #print (np.unique(kmeans.labels_))\n",
    "        #X_train[m]= kmeans.labels_\n",
    "        #IO_points = kmeans.cluster_centers_\n",
    "        IO_points ,C = MLIO_MIQCP(A,b,XT,n + 1)\n",
    "        #IO_points = IO_points.reshape(n+1,2)\n",
    "        centroids = np.zeros ([n+1,2])\n",
    "        for i in range(n+1):\n",
    "            centroids [i,0] = IO_points[i]\n",
    "            centroids [i,1] = IO_points[n+1+i]\n",
    "        if (X.shape[0] ==2) or (X.shape[1] ==2):\n",
    "            plot_coloured_clusters(X,centroids,count)\n",
    "        count += 1 \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster(X, X_train):\n",
    "    dist_min = -1\n",
    "    m = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    X_test = np.zeros ([m+1,k])\n",
    "    X_test[0:m]= X\n",
    "    X_testT = X_test.T\n",
    "    X_trainT = X_train.T\n",
    "    temp = np.array([])\n",
    "    iteration = 0\n",
    "    for i in range(X_testT.shape[0]):\n",
    "        iteration = 0\n",
    "        dist_min = -1\n",
    "        for j in np.unique(X_train.T[:,m]):\n",
    "            dist = 0\n",
    "            count = 0\n",
    "            for n in range(X_train.T.shape[0]):\n",
    "                if X_trainT[n,m] == j:\n",
    "                    #dist += np.linalg.norm(X_testT[i,0:m] - X_trainT[n,0:m]) \n",
    "                    dist += sum (abs (X_testT[i,0:m] - X_trainT[n,0:m]))\n",
    "                    count += 1\n",
    "            dist = dist / count\n",
    "            if iteration == 0: \n",
    "                dist_min = dist\n",
    "                iteration +=1\n",
    "                X_test[m,i] = j\n",
    "            elif dist < dist_min: \n",
    "                dist_min = dist\n",
    "                X_test[m,i] = j\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEQ_MLIO_2D(A,b,X,X_test, max_number_of_clusters,figure):\n",
    "    m = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    X_train = np.zeros ([m+1,k])\n",
    "    X_train[0:m]= X\n",
    "    XT = X.T        \n",
    "    #max_number_of_clusters = 8\n",
    "    dif =                   np.zeros (max_number_of_clusters)\n",
    "    dif_train =             np.zeros (max_number_of_clusters)\n",
    "    dif_test =              np.zeros (max_number_of_clusters)\n",
    "    opt_gap =               np.zeros (max_number_of_clusters)\n",
    "    dif_train_cluster_avg = np.zeros (max_number_of_clusters)\n",
    "    dif_train_cluster_avg_1 = np.zeros (max_number_of_clusters)\n",
    "    dif_train_cluster_avg_2 = np.zeros (max_number_of_clusters)\n",
    "    IO_points_dic = {}\n",
    "    #sodium_ML = np.zeros ([max_number_of_clusters, max_number_of_clusters,nutrient_names.shape[0]])\n",
    "    #sodium_disjoint = np.zeros ([max_number_of_clusters, max_number_of_clusters,nutrient_names.shape[0]])\n",
    "    count = 0  \n",
    "    for n in range(max_number_of_clusters):\n",
    "        IO_points_dic[str(n+1)+'_cluster_centers'] = {}\n",
    "        kmeans = KMeans(n_clusters=n + 1, random_state=0).fit(XT)\n",
    "        #print (np.unique(kmeans.labels_))\n",
    "        X_train[m]= kmeans.labels_\n",
    "        kmeans.cluster_centers_\n",
    "        if False:\n",
    "            X_train, centers_new = Direct_Kmeans(X, X_test, 2, \"no\",  0.01,  20)\n",
    "        X_test_labeled = find_cluster(X_test, X_train)\n",
    "        #X_test_labeled[m] = kmeans.predict (X_test.T)\n",
    "        unique_cluster = np.unique(X_train[m])\n",
    "        IO_points = np.array ([])\n",
    "        Cluster_avg = np.array ([])\n",
    "        for i in range (np.max(np.unique(kmeans.labels_))+1):\n",
    "        #for i in unique_cluster:\n",
    "            X1 = X_train.T[X_train.T[:,m] == i]\n",
    "            X1 = X1[:,0:m].T\n",
    "            Z1, C1 = IO(A,b,X1.T)\n",
    "            IO_points = np.append (IO_points,Z1)\n",
    "            IO_points_dic[str(n+1)+'_cluster_centers'][i] = Z1\n",
    "            ii = int(i)\n",
    "            #print ('i: ' + str(i))\n",
    "            #print ('ii: ' + str(ii))\n",
    "            if A.shape[0] >=20:\n",
    "                for j in range(nutrient_names.shape[0]):\n",
    "                    sodium_ML[n][ii][j] = A[j].dot(kmeans.cluster_centers_[ii])\n",
    "                    sodium_disjoint[n][ii][j] = A[j].dot(Z1)\n",
    "            x_mean = np.zeros([m])\n",
    "            if X1!= []:\n",
    "                dif_train[n] += sum (sum (abs (X1.T - Z1)))\n",
    "                for j in range(m):\n",
    "                    x_mean[j] = X1.T[:,j].mean()\n",
    "                Cluster_avg = np.append (Cluster_avg,x_mean)\n",
    "                opt_gap[n]   += abs(abs(C1.dot(Z1)) - abs(C1.dot(X1))).sum()\n",
    "                #dif_train_cluster_avg_1[n] += sum (sum (abs (X1.T - x_mean)))\n",
    "                #dif_train_cluster_avg_1[n] += np.linalg.norm(X1.T- kmeans.cluster_centers_[i])\n",
    "                dif_train_cluster_avg_2[n] += sum (sum (abs (X1.T - kmeans.cluster_centers_[i])))\n",
    "                if A.shape[0] >=20:\n",
    "                    for j in range(nutrient_names.shape[0]):\n",
    "                        sodium_ML[n][ii][j] = A[j].dot(kmeans.cluster_centers_[ii])\n",
    "                        sodium_disjoint[n][ii][j] = A[j].dot(Z1)\n",
    "                for j in range(X1.T.shape[0]):\n",
    "                    dif_train_cluster_avg_1[n] += np.linalg.norm(X1.T[j]- kmeans.cluster_centers_[i])\n",
    "#out_of_sample testing error\n",
    "            X_test_labeled1 = X_test_labeled.T[X_test_labeled.T[:,m] == i]\n",
    "            X_test_labeled1 = X_test_labeled1[:,0:m].T\n",
    "            if X_test_labeled1.shape[1] > 0 :\n",
    "                dif_test[n] += sum (sum (abs (X_test_labeled1.T - Z1)))   \n",
    "        if (X.shape[0] ==2):\n",
    "            plot_coloured_clusters(X,IO_points.reshape(int(IO_points.shape[0]/2),2),count)\n",
    "        count += 1    \n",
    "        \n",
    "            \n",
    "        \n",
    "        if (X.shape[0] ==2) and figure:\n",
    "            fig = plt.figure(figsize=(6,12))\n",
    "            ax = fig.add_axes([0, 0, 1, 1])\n",
    "            colors = ['r','g','b','c','m', 'y', 'k']\n",
    "            s = 150\n",
    "            for i in range (n+1):\n",
    "                ci = colors[i]\n",
    "                plt.scatter(IO_points[2*i], IO_points[2*i+1], marker=',', c=ci, s=300,\n",
    "                       edgecolor=\"black\", label=\"IO_point\")\n",
    "                plt.scatter(Cluster_avg[2*i], Cluster_avg[2*i+1],marker='x', c=ci, s=300,\n",
    "                       edgecolor=\"black\", label=\"Cluster_avg\")\n",
    "        #    plt.scatter(X[0, :], X[1, :], c=\"navy\", s=s,\n",
    "        #                edgecolor=\"black\", label=\"data\")\n",
    "            count = 0\n",
    "            for i in unique_cluster:\n",
    "                ci = colors[count]\n",
    "                X1 = X_train.T[X_train.T[:,2] == i]\n",
    "                X1 = X1.T\n",
    "                plt.scatter(X1[0, :], X1[1, :], c=ci,s=s,\n",
    "                        edgecolor=\"black\", label=\"data\")\n",
    "                count +=1\n",
    "        #    plt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=500, edgecolor=\"black\")\n",
    "            plt.xlim([0, 6])\n",
    "            plt.ylim([0, 11])\n",
    "            plt.plot([1,1], [1, 10], c=\"navy\", linewidth=3)\n",
    "            plt.plot([5,5], [1, 10], c=\"navy\", linewidth=3)\n",
    "            plt.plot([1,5], [10, 10], c=\"navy\", linewidth=3)\n",
    "            plt.plot([1,5], [1, 1], c=\"navy\", linewidth=3)\n",
    "            ax.fill_between([1,5], [10,10], [1,1], facecolor='black', alpha=0.05)\n",
    "            ax.set_xlabel('x1')\n",
    "            ax.set_ylabel('x2')\n",
    "            #plt.savefig('Saved_figures/UL2Dfig' + str(n) +'.png')\n",
    "    return X_train, dif_train, opt_gap, dif_train_cluster_avg_1,dif_train_cluster_avg_2, dif_test,IO_points, Cluster_avg,x_mean\n",
    "# X_train contains the original data and the final cluster labels\n",
    "# dif_train is the sum of distances from the observations to the optimal inferred solutions\n",
    "# opt_gap calculates the sum of optimality gaps of all the observations from their optimal obj values\n",
    "# dif_train_cluster_avg contains the sum of the distances of the observations from their cluster averages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Embedded_partition_learn(A,b,X, X_test, max_number_of_clusters,figure):\n",
    "    data = X.T\n",
    "    #max_number_of_clusters = 8\n",
    "    # Number of training data\n",
    "    n = data.shape[0]\n",
    "    # Number of features in the data\n",
    "    c = data.shape[1]\n",
    "    opt_gap_emb = np.zeros (max_number_of_clusters)\n",
    "    mean = np.mean(data, axis = 0)\n",
    "    std = np.std(data, axis = 0)\n",
    "    dif = np.zeros (max_number_of_clusters)\n",
    "    dif_train_base = np.zeros (max_number_of_clusters)\n",
    "    dif_test =       np.zeros (max_number_of_clusters)\n",
    "    #sodium_embedded = np.zeros ([max_number_of_clusters, max_number_of_clusters,nutrient_names.shape[0]])\n",
    "    for k in range(1,max_number_of_clusters+1):\n",
    "        #centers = np.random.randn(k,c)*std + mean\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0).fit(data)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        centers_old = np.zeros(centers.shape) # to store old centers\n",
    "        centers_new = deepcopy(centers) # Store new centers\n",
    "        centers_best = deepcopy(centers) # Store best centers\n",
    "        C1 = deepcopy(centers)\n",
    "        clusters = np.zeros(n)\n",
    "        distances = np.zeros((n,k))\n",
    "        error = np.linalg.norm(centers_new - centers_old)\n",
    "        IO_points = np.zeros ([1])\n",
    "        Cluster_avg = np.zeros ([1])\n",
    "        temp_error_old = 0\n",
    "        temp_error_new = 0\n",
    "        plt.figure()\n",
    "        for i in range(k):\n",
    "            data_temp = data[clusters == i]\n",
    "    #         plt.scatter(data_temp[:,0], data_temp[:,1], s=7)\n",
    "    #     #plt.scatter(data[:,0], data[:,1], s=7)\n",
    "    #     plt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)\n",
    "    #     plt.xlim([0, 5])\n",
    "    #     plt.ylim([0, 5])\n",
    "    #     plt.plot([0,3], \n",
    "    #             [5, 2])\n",
    "    #     plt.plot([3,3], \n",
    "    #             [0, 2])\n",
    "        # When, after an update, the estimate of that center stays the same, exit loop\n",
    "        #while error != 0:\n",
    "        count = 0\n",
    "        count_2 = 0\n",
    "        while error >= 0.001 and count < 200:\n",
    "            count +=1 \n",
    "            # Measure the distance to every center \n",
    "            for i in range(k):\n",
    "                distances[:,i] = np.linalg.norm(data - centers_new[i], axis=1, ord = 1)\n",
    "            # Assign all training data to closest center\n",
    "            clusters = np.argmin(distances, axis = 1)\n",
    "            centers_old = deepcopy(centers_new)\n",
    "            # Calculate mean for every cluster and update the center\n",
    "            for i in range(k):\n",
    "                centers_new[i] , C1[i] = IO(A,b,data[clusters == i])\n",
    "            error = np.linalg.norm(centers_new - centers_old)\n",
    "            if count == 1: \n",
    "                for i in range(n):\n",
    "                    dif[k-1] += np.min(distances[i,:])\n",
    "            if count >= 2:\n",
    "                for i in range(n):\n",
    "                    temp_error_new += np.min(distances[i,:])\n",
    "                if temp_error_new<=dif[k-1]:\n",
    "                    #centers_best = centers_new\n",
    "                    dif[k-1] = temp_error_new\n",
    "                    temp_error_new =0\n",
    "        for i in range(n):\n",
    "            dif_train_base[k-1] += np.min(distances[i,:])\n",
    "        for i in range(k):\n",
    "            data_temp = data[clusters == i]\n",
    "            #opt_gap_emb[k-1]   += abs(abs(C1[i].dot(centers_new[i]))- abs(C1[i].dot(data_temp.T))).sum()\n",
    "            opt_gap_emb[k-1]   += abs(C1[i].dot(centers_new[i])- C1[i].dot(data_temp.T)).sum()\n",
    "        \n",
    "        X_train = np.append (data.T,clusters)\n",
    "        X_train = X_train.reshape(c+1,n)\n",
    "        X_test_labeled = find_cluster(X_test, X_train)\n",
    "        #print('x_test :' , X_test_labeled.T)\n",
    "        for i in np.unique(clusters):\n",
    "            X_test_labeled1 = X_test_labeled.T[X_test_labeled.T[:,c] == i]\n",
    "            X_test_labeled1 = X_test_labeled1[:,0:c].T\n",
    "            if X_test_labeled1.shape[1] > 0 :\n",
    "                dif_test[k-1] += sum (sum (abs (X_test_labeled1.T - centers_new[i])))   \n",
    "            if A.shape[1] >2:\n",
    "                for j in range(nutrient_names.shape[0]):\n",
    "                    sodium_embedded[k-1][i][j] = A[j].dot(centers_new[i])\n",
    "        if (X.shape[0] ==2):\n",
    "            plot_coloured_clusters(X,centers_new,count_2)\n",
    "            count_2+=1         \n",
    "    return dif,dif_train_base, centers_new, opt_gap_emb, data, dif_test, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function: IO Code (Distance Norm =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IO(A,b,X):\n",
    "    m1 = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    K = X.shape[0]\n",
    "    AT = A.T\n",
    "    num_var = 2 * K * n + 3 * n + m1\n",
    "    m = gp.Model(\"IO\")\n",
    "    m.Params.timeLimit = 100.0\n",
    "    m.Params.OutputFlag = 0\n",
    "    # Create variables\n",
    "    e = m.addVars(K,n,  lb=-GRB.INFINITY, name = 'e')\n",
    "    t = m.addVars(K,n,  lb=-GRB.INFINITY, name = 't')\n",
    "    c = m.addVars(n,  lb=-GRB.INFINITY, name = 'c')\n",
    "    y = m.addVars(m1,  lb=-GRB.INFINITY, name = 'y')\n",
    "    d = m.addVars(n,  lb=-GRB.INFINITY, name = 'd')\n",
    "    z = m.addVars(n, name = 'z')\n",
    "\n",
    "\n",
    "    # Set objective:\n",
    "    m.setObjective(gp.quicksum(t[k,i] for k in range (K) for i in range(n)), GRB.MINIMIZE)\n",
    "    # Constraints \n",
    "    for k in range (K):\n",
    "        m.addConstrs(t[k,i] >= e[k,i] for i in range(n))\n",
    "        m.addConstrs(t[k,i] >= -e[k,i] for i in range(n))\n",
    "        m.addConstrs(X[k,i] - e[k,i]  == z[i] for i in range(n))\n",
    "    for j in range(m1):\n",
    "        m.addConstr(gp.quicksum(A[j,i] * z[i] for i in range(n)) <= b[j])\n",
    "    for i in range(n):\n",
    "        m.addConstr(gp.quicksum(y[j] * A[j,i] for j in range(m1)) == c[i])    \n",
    "    m.addConstrs(y[j] >= 0 for j in range(m1))\n",
    "    m.addConstr(gp.quicksum(c[j] * z[j] for j in range(n)) == gp.quicksum(b[i] * y[i] for i in range(m1)))\n",
    "    for i in range(n):\n",
    "        m.addConstr(d[i] == gp.abs_(c[i]))\n",
    "    m.addConstr(gp.quicksum(d[i] for i in range(n)) == 1)  \n",
    "    m.params.NonConvex = 2   \n",
    "    m.optimize()\n",
    "    vars = m.getVars()\n",
    "    #for i in range (n):\n",
    "    #    print (vars [num_var -1 -(n-1-i)])\n",
    "#     n = A.shape[1]\n",
    "    Z = np.zeros (n)\n",
    "    C = np.zeros (n)\n",
    "    count = 0\n",
    "    for v in z.values():\n",
    "        Z[count] = v.X\n",
    "        count += 1\n",
    "    count = 0\n",
    "    for v in c.values():\n",
    "        C[count] = v.X\n",
    "        count += 1\n",
    "    return Z, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMB_MLIO_MIQCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMB_MLIO_MIQCP(A,b,X,num_clusters):\n",
    "    m1 = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    K = X.shape[0]\n",
    "    L = num_clusters\n",
    "    AT = A.T\n",
    "    num_var = 2 * K * n + 3 * n + m1\n",
    "    m = gp.Model(\"IO\")\n",
    "    m.Params.timeLimit = 100.0\n",
    "    m.Params.OutputFlag = 0\n",
    "    # Create variables\n",
    "    e = m.addVars(K,n,  lb=-GRB.INFINITY, name = 'e')\n",
    "    t = m.addVars(K,n,  lb=-GRB.INFINITY, name = 't')\n",
    "    c = m.addVars(n,L,  lb=-GRB.INFINITY, name = 'c')\n",
    "    y = m.addVars(m1,L,  lb=-GRB.INFINITY, name = 'y')\n",
    "    d = m.addVars(n,  lb=-GRB.INFINITY, name = 'd')\n",
    "    z = m.addVars(n,L, name = 'z')\n",
    "\n",
    "\n",
    "    # Set objective:\n",
    "    m.setObjective(gp.quicksum(t[k,i] for k in range (K) for i in range(n)), GRB.MINIMIZE)\n",
    "    # Constraints\n",
    "    \n",
    "    for k in range (K):\n",
    "        m.addConstrs(t[k,i] >= e[k,i] for i in range(n))\n",
    "        m.addConstrs(t[k,i] >= -e[k,i] for i in range(n))\n",
    "    for k in range (K):\n",
    "        for l in range (L):\n",
    "            m.addConstrs( (X[k,i] - e[k,i]) * v[k,l]  == z[i,l] * v[k,l] for i in range(n))\n",
    "    for j in range(m1):\n",
    "        for l in range (L):\n",
    "            m.addConstr(gp.quicksum(A[j,i] * z[i,l] for i in range(n)) <= b[j])\n",
    "    for i in range(n):\n",
    "        for l in range (L):\n",
    "            m.addConstr(gp.quicksum(y[j,l] * A[j,i] for j in range(m1)) == c[i,l])    \n",
    "    m.addConstrs(y[j,l] >= 0 for j in range(m1) for l in range (L) )\n",
    "    for l in range (L):\n",
    "        m.addConstr(gp.quicksum(c[j,l] * z[j,l] for j in range(n)) == gp.quicksum(b[i] * y[i,l] for i in range(m1)))\n",
    "    #for i in range(n):\n",
    "    #    m.addConstr(d[i] == gp.abs_(c[i]))\n",
    "    #m.addConstr(gp.quicksum(d[i] for i in range(n)) == 1)  \n",
    "    for l in range (L):\n",
    "        m.addConstr(gp.quicksum(y[j,l]  for j in range(m1)) == 1)\n",
    "    m.params.NonConvex = 2   \n",
    "    m.optimize()\n",
    "    vars = m.getVars()\n",
    "    #for i in range (n):\n",
    "    #    print (vars [num_var -1 -(n-1-i)])\n",
    "#     n = A.shape[1]\n",
    "    Z = np.zeros (n)\n",
    "    C = np.zeros (n)\n",
    "    count = 0\n",
    "    for v in z.values():\n",
    "        Z[count] = v.X\n",
    "        count += 1\n",
    "    count = 0\n",
    "    for v in c.values():\n",
    "        C[count] = v.X\n",
    "        count += 1\n",
    "    return Z, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function: Direct K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Direct_Kmeans(X, X_test, number_of_clusters, IO, Error = 0.01, Iterations = 20):\n",
    "    k = number_of_clusters\n",
    "    data = X.T\n",
    "    #max_number_of_clusters = 8\n",
    "    # Number of training data\n",
    "    n = data.shape[0]\n",
    "    # Number of features in the data\n",
    "    c = data.shape[1]\n",
    "    mean = np.mean(data, axis = 0)\n",
    "    std = np.std(data, axis = 0)\n",
    "    centers = np.random.randn(number_of_clusters,c)*std + mean\n",
    "    centers_old = np.zeros(centers.shape) # to store old centers\n",
    "    centers_new = deepcopy(centers) # Store new centers\n",
    "    C1 = deepcopy(centers)\n",
    "    clusters = np.zeros(n)\n",
    "    distances = np.zeros((n,k))\n",
    "    error = np.linalg.norm(centers_new - centers_old)\n",
    "    IO_points = np.zeros ([1])\n",
    "    Cluster_avg = np.zeros ([1])\n",
    "    plt.figure()\n",
    "    count = 0\n",
    "    while error >= Error and count < Iterations:\n",
    "        count +=1 \n",
    "        # Measure the distance to every center \n",
    "        for i in range(k):\n",
    "            distances[:,i] = np.linalg.norm(data - centers_new[i], axis=1, ord = 1)\n",
    "        # Assign all training data to closest center\n",
    "        clusters = np.argmin(distances, axis = 1)\n",
    "        centers_old = deepcopy(centers_new)\n",
    "        # Calculate mean for every cluster and update the center\n",
    "        for i in range(k):\n",
    "            if IO == \"yes\":\n",
    "                centers_new[i] , C1[i] = IO(A,b,data[clusters == i])\n",
    "            else:\n",
    "                centers_new[i] = np.mean(data[clusters == i], axis=0)\n",
    "        error = np.linalg.norm(centers_new - centers_old)\n",
    "    for i in range(k):\n",
    "        distances[:,i] = np.linalg.norm(data - centers_new[i], axis=1, ord = 1)\n",
    "        clusters = np.argmin(distances, axis = 1)\n",
    "    X_train = np.append (data.T,clusters)\n",
    "    X_train = X_train.reshape(c+1,n)\n",
    "    if IO == \"yes\":\n",
    "        return X_train, centers_new, C1\n",
    "    else:\n",
    "        return X_train, centers_new\n",
    "    \n",
    "#     for i in range(n):\n",
    "#         dif_train_base[k-1] += np.min(distances[i,:])\n",
    "#     for i in range(k):\n",
    "#         data_temp = data[clusters == i]\n",
    "#         #opt_gap_emb[k-1]   += abs(abs(C1[i].dot(centers_new[i]))- abs(C1[i].dot(data_temp.T))).sum()\n",
    "#         opt_gap_emb[k-1]   += abs(C1[i].dot(centers_new[i])- C1[i].dot(data_temp.T)).sum()\n",
    "#     X_train = np.append (data.T,clusters)\n",
    "#     X_train = X_train.reshape(c+1,n)\n",
    "#     X_test_labeled = find_cluster(X_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13157ef4088>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set three centers, the model should predict similar results\n",
    "center_1 = np.array([1,1])\n",
    "center_2 = np.array([2.5,1])\n",
    "center_3 = np.array([1.5,3])\n",
    "\n",
    "# Generate random data and center it to the three centers\n",
    "data_1 = 0.3*np.random.randn(20, 2) + center_1\n",
    "data_2 = 0.3*np.random.randn(20,2) + center_2\n",
    "data_3 = 0.3*np.random.randn(20,2) + center_3\n",
    "\n",
    "data = np.concatenate((data_1, data_2, data_3), axis = 0)\n",
    "plt.scatter(data[:,0], data[:,1], s=25)\n",
    "plt.xlim([0, 5])\n",
    "plt.ylim([0, 5])\n",
    "plt.plot([0,3], \n",
    "        [5, 2])\n",
    "plt.plot([3,3], \n",
    "        [0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, centers_new = Direct_Kmeans(data.T, data, 2, \"no\",  0.01,  20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 60)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.T.shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65910975, 1.03514149, 0.        ],\n",
       "       [1.3003745 , 0.56866745, 0.        ],\n",
       "       [1.27928709, 0.84082204, 0.        ],\n",
       "       [0.71278767, 0.78829576, 0.        ],\n",
       "       [1.23987716, 0.93212777, 0.        ],\n",
       "       [0.8103149 , 1.24167694, 0.        ],\n",
       "       [0.59151192, 0.64201229, 0.        ],\n",
       "       [1.06926525, 0.87555973, 0.        ],\n",
       "       [0.84895303, 0.52379902, 0.        ],\n",
       "       [1.20008628, 0.75412433, 0.        ],\n",
       "       [1.34606652, 0.9301489 , 0.        ],\n",
       "       [1.04419919, 0.38251901, 0.        ],\n",
       "       [1.36172892, 0.39572983, 0.        ],\n",
       "       [1.06785246, 0.54023324, 0.        ],\n",
       "       [0.84224345, 0.85100369, 0.        ],\n",
       "       [0.88251873, 0.48567705, 0.        ],\n",
       "       [0.15937069, 1.37527065, 0.        ],\n",
       "       [0.90216176, 0.71695129, 0.        ],\n",
       "       [0.7148784 , 0.58035348, 0.        ],\n",
       "       [0.7514845 , 1.05066839, 0.        ],\n",
       "       [2.54984641, 1.24671088, 0.        ],\n",
       "       [2.65876989, 1.31675263, 0.        ],\n",
       "       [2.91401592, 0.97620608, 0.        ],\n",
       "       [2.49216646, 1.83060376, 0.        ],\n",
       "       [2.31079533, 1.23104977, 0.        ],\n",
       "       [3.03469336, 1.13763784, 0.        ],\n",
       "       [2.29216135, 0.92677708, 0.        ],\n",
       "       [2.20476563, 1.21356086, 0.        ],\n",
       "       [2.26895732, 0.93648361, 0.        ],\n",
       "       [2.34926276, 0.60304057, 0.        ],\n",
       "       [2.49469319, 1.45786806, 0.        ],\n",
       "       [1.84761703, 0.6826275 , 0.        ],\n",
       "       [2.43588605, 0.58268808, 0.        ],\n",
       "       [2.60713253, 0.97050939, 0.        ],\n",
       "       [2.45296911, 1.13729684, 0.        ],\n",
       "       [2.25074483, 1.31632218, 0.        ],\n",
       "       [2.23319531, 0.83128729, 0.        ],\n",
       "       [2.33484828, 1.17615043, 0.        ],\n",
       "       [2.48330289, 1.3389035 , 0.        ],\n",
       "       [2.58775302, 0.49033355, 0.        ],\n",
       "       [1.2587911 , 2.88977082, 1.        ],\n",
       "       [1.49283298, 3.43360025, 1.        ],\n",
       "       [1.25723618, 3.12461382, 1.        ],\n",
       "       [0.93273067, 2.88598281, 1.        ],\n",
       "       [1.19696325, 2.34689964, 1.        ],\n",
       "       [1.59195311, 2.63801424, 1.        ],\n",
       "       [1.90441816, 3.55884395, 1.        ],\n",
       "       [1.56366789, 3.29553768, 1.        ],\n",
       "       [1.47688931, 3.23081147, 1.        ],\n",
       "       [1.6832626 , 3.21207256, 1.        ],\n",
       "       [1.39755983, 3.06967427, 1.        ],\n",
       "       [1.75323771, 2.9478001 , 1.        ],\n",
       "       [1.64422466, 2.6045833 , 1.        ],\n",
       "       [1.70156824, 2.88356675, 1.        ],\n",
       "       [1.19392387, 3.01211162, 1.        ],\n",
       "       [1.50428126, 2.94237416, 1.        ],\n",
       "       [1.63238803, 2.96202077, 1.        ],\n",
       "       [1.48791294, 2.94542733, 1.        ],\n",
       "       [1.42365029, 3.3153089 , 1.        ],\n",
       "       [1.27883849, 3.40304887, 1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function: Independent partition, Use centers as input to IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ind_partition_learn_Centers_to_IO(A,b,X, X_test, min_number_of_clusters, max_number_of_clusters, Testing):\n",
    "    m = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    X_train = np.zeros ([m+1,k])\n",
    "    X_train[0:m]= X\n",
    "    XT = X.T\n",
    "    for n in range(max_number_of_clusters):\n",
    "        IO_points_dic[str(n+1)+'_cluster_centers'] = {}\n",
    "        kmeans = KMeans(n_clusters=n + 1, random_state=0).fit(XT)\n",
    "        kmeans.labels_\n",
    "        X_train[m]= kmeans.labels_\n",
    "        kmeans.cluster_centers_\n",
    "        X_test_labeled = find_cluster(X_test, X_train)\n",
    "        X_test_labeled[m] = kmeans.predict (X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function: Independent Partition and Learning Model: Ind_partition_learn(A,b,X, max_number_of_clusters)\n",
    "## partition then optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ind_partition_learn(A,b,X, X_test, max_number_of_clusters,figure):\n",
    "    m = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    X_train = np.zeros ([m+1,k])\n",
    "    X_train[0:m]= X\n",
    "    XT = X.T        \n",
    "    #max_number_of_clusters = 8\n",
    "    dif =                   np.zeros (max_number_of_clusters)\n",
    "    dif_train =             np.zeros (max_number_of_clusters)\n",
    "    dif_test =              np.zeros (max_number_of_clusters)\n",
    "    opt_gap =               np.zeros (max_number_of_clusters)\n",
    "    dif_train_cluster_avg = np.zeros (max_number_of_clusters)\n",
    "    IO_points_dic = {}\n",
    "    for n in range(max_number_of_clusters):\n",
    "        IO_points_dic[str(n+1)+'_cluster_centers'] = {}\n",
    "        kmeans = KMeans(n_clusters=n + 1, random_state=0).fit(XT)\n",
    "        kmeans.labels_\n",
    "        X_train[m]= kmeans.labels_\n",
    "        kmeans.cluster_centers_\n",
    "        X_test_labeled = find_cluster(X_test, X_train)\n",
    "        X_test_labeled[m] = kmeans.predict (X_test.T)\n",
    "        unique_cluster = np.unique(X_train[m])\n",
    "        IO_points = np.array ([])\n",
    "        Cluster_avg = np.array ([])\n",
    "        for i in unique_cluster:\n",
    "            X1 = X_train.T[X_train.T[:,m] == i]\n",
    "            X1 = X1[:,0:m].T\n",
    "            Z1, C1 = IO(A,b,X1.T)\n",
    "            IO_points = np.append (IO_points,Z1)\n",
    "            IO_points_dic[str(n+1)+'_cluster_centers'][i] = Z1\n",
    "            x_mean = np.zeros([m])\n",
    "            dif_train[n] += sum (sum (abs (X1.T - Z1)))\n",
    "            for j in range(m):\n",
    "                x_mean[j] = X1.T[:,j].mean()\n",
    "            Cluster_avg = np.append (Cluster_avg,x_mean)\n",
    "            opt_gap[n]   += abs(abs(C1.dot(Z1)) - abs(C1.dot(X1))).sum()\n",
    "            dif_train_cluster_avg[n] += sum (sum (abs (X1.T - x_mean)))\n",
    "#out_of_sample testing error\n",
    "            X_test_labeled1 = X_test_labeled.T[X_test_labeled.T[:,m] == i]\n",
    "            X_test_labeled1 = X_test_labeled1[:,0:m].T\n",
    "            if X_test_labeled1.shape[1] > 0 :\n",
    "                dif_test[n] += sum (sum (abs (X_test_labeled1.T - Z1)))   \n",
    "        if (X.shape[0] ==2) and figure:\n",
    "            fig = plt.figure(figsize=(6,12))\n",
    "            ax = fig.add_axes([0, 0, 1, 1])\n",
    "            colors = ['r','g','b','c','m', 'y', 'k']\n",
    "            s = 150\n",
    "            for i in range (n+1):\n",
    "                ci = colors[i]\n",
    "                plt.scatter(IO_points[2*i+1], IO_points[2*i+2], marker=',', c=ci, s=300,\n",
    "                       edgecolor=\"black\", label=\"IO_point\")\n",
    "                plt.scatter(Cluster_avg[2*i+1], Cluster_avg[2*i+2],marker='x', c=ci, s=300,\n",
    "                       edgecolor=\"black\", label=\"Cluster_avg\")\n",
    "        #    plt.scatter(X[0, :], X[1, :], c=\"navy\", s=s,\n",
    "        #                edgecolor=\"black\", label=\"data\")\n",
    "            count = 0\n",
    "            for i in unique_cluster:\n",
    "                ci = colors[count]\n",
    "                X1 = X_train.T[X_train.T[:,2] == i]\n",
    "                X1 = X1.T\n",
    "                plt.scatter(X1[0, :], X1[1, :], c=ci,s=s,\n",
    "                        edgecolor=\"black\", label=\"data\")\n",
    "                count +=1\n",
    "        #    plt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=500, edgecolor=\"black\")\n",
    "            plt.xlim([0, 6])\n",
    "            plt.ylim([0, 11])\n",
    "            plt.plot([1,1], [1, 10], c=\"navy\", linewidth=3)\n",
    "            plt.plot([5,5], [1, 10], c=\"navy\", linewidth=3)\n",
    "            plt.plot([1,5], [10, 10], c=\"navy\", linewidth=3)\n",
    "            plt.plot([1,5], [1, 1], c=\"navy\", linewidth=3)\n",
    "            ax.fill_between([1,5], [10,10], [1,1], facecolor='black', alpha=0.05)\n",
    "            ax.set_xlabel('x1')\n",
    "            ax.set_ylabel('x2')\n",
    "            plt.savefig('Saved_figures/UL2Dfig' + str(n) +'.png')\n",
    "    return X_train, dif_train, opt_gap, dif_train_cluster_avg, dif_test,IO_points, Cluster_avg,x_mean\n",
    "# X_train contains the original data and the final cluster labels\n",
    "# dif_train is the sum of distances from the observations to the optimal inferred solutions\n",
    "# opt_gap calculates the sum of optimality gaps of all the observations from their optimal obj values\n",
    "# dif_train_cluster_avg contains the sum of the distances of the observations from their cluster averages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function: Embedded Partition and Learning Model: Embedded_partition_learn(A,b,X, max_number_of_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Embedded_partition_learn_2(A,b,X, X_test, max_number_of_clusters,figure):\n",
    "    data = X.T\n",
    "    #max_number_of_clusters = 8\n",
    "    # Number of training data\n",
    "    n = data.shape[0]\n",
    "    # Number of features in the data\n",
    "    c = data.shape[1]\n",
    "    opt_gap_emb = np.zeros (max_number_of_clusters)\n",
    "    mean = np.mean(data, axis = 0)\n",
    "    std = np.std(data, axis = 0)\n",
    "    dif = np.zeros (max_number_of_clusters)\n",
    "    dif_train_base = np.zeros (max_number_of_clusters)\n",
    "    dif_test =       np.zeros (max_number_of_clusters)\n",
    "    for k in range(1,max_number_of_clusters+1):\n",
    "        centers = np.random.randn(k,c)*std + mean\n",
    "        centers_old = np.zeros(centers.shape) # to store old centers\n",
    "        centers_new = deepcopy(centers) # Store new centers\n",
    "        C1 = deepcopy(centers)\n",
    "        clusters = np.zeros(n)\n",
    "        distances = np.zeros((n,k))\n",
    "        error = np.linalg.norm(centers_new - centers_old)\n",
    "        IO_points = np.zeros ([1])\n",
    "        Cluster_avg = np.zeros ([1])\n",
    "        plt.figure()\n",
    "        for i in range(k):\n",
    "            data_temp = data[clusters == i]\n",
    "    #         plt.scatter(data_temp[:,0], data_temp[:,1], s=7)\n",
    "    #     #plt.scatter(data[:,0], data[:,1], s=7)\n",
    "    #     plt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)\n",
    "    #     plt.xlim([0, 5])\n",
    "    #     plt.ylim([0, 5])\n",
    "    #     plt.plot([0,3], \n",
    "    #             [5, 2])\n",
    "    #     plt.plot([3,3], \n",
    "    #             [0, 2])\n",
    "        # When, after an update, the estimate of that center stays the same, exit loop\n",
    "        #while error != 0:\n",
    "        count = 0\n",
    "        while error >= 0.01 and count < 20:\n",
    "            count +=1 \n",
    "            # Measure the distance to every center \n",
    "            for i in range(k):\n",
    "                distances[:,i] = np.linalg.norm(data - centers_new[i], axis=1, ord = 1)\n",
    "            # Assign all training data to closest center\n",
    "            clusters = np.argmin(distances, axis = 1)\n",
    "            centers_old = deepcopy(centers_new)\n",
    "            # Calculate mean for every cluster and update the center\n",
    "            for i in range(k):\n",
    "                centers_new[i] , C1[i] = IO(A,b,data[clusters == i])\n",
    "            error = np.linalg.norm(centers_new - centers_old)\n",
    "        for i in range(n):\n",
    "            dif_train_base[k-1] += np.min(distances[i,:])\n",
    "        for i in range(k):\n",
    "            data_temp = data[clusters == i]\n",
    "            #opt_gap_emb[k-1]   += abs(abs(C1[i].dot(centers_new[i]))- abs(C1[i].dot(data_temp.T))).sum()\n",
    "            opt_gap_emb[k-1]   += abs(C1[i].dot(centers_new[i])- C1[i].dot(data_temp.T)).sum()\n",
    "        \n",
    "        X_train = np.append (data.T,clusters)\n",
    "        X_train = X_train.reshape(c+1,n)\n",
    "        X_test_labeled = find_cluster(X_test, X_train)\n",
    "        for i in np.unique(clusters):\n",
    "            X_test_labeled1 = X_test_labeled.T[X_test_labeled.T[:,c] == i]\n",
    "            X_test_labeled1 = X_test_labeled1[:,0:c].T\n",
    "            if X_test_labeled1.shape[1] > 0 :\n",
    "                dif_test[k-1] += sum (sum (abs (X_test_labeled1.T - centers_new[i,:])))   \n",
    "#figure\n",
    "        if (X.shape[0] ==2) and figure:\n",
    "            plt.rcParams['font.size'] = 14\n",
    "            plt.rcParams['axes.linewidth'] = 3\n",
    "            # Create figure object and store it in a variable called 'fig'\n",
    "            fig = plt.figure(figsize=(6, 12))\n",
    "            ax = fig.add_axes([0, 0, 1, 1])\n",
    "            colors = ['r','g','b','c','m', 'y', 'k']\n",
    "            for i in range(k):\n",
    "                ci = colors[i]\n",
    "                data_temp = data[clusters == i]\n",
    "                plt.scatter(data_temp[:,0], data_temp[:,1], c=ci, s=150, edgecolor=\"black\")\n",
    "            #plt.scatter(data[:,0], data[:,1], s=7)\n",
    "                plt.scatter(centers_new[i,0], centers_new[i,1], marker=',', c=ci, s=500, edgecolor=\"black\")\n",
    "            plt.xlim([0, 6])\n",
    "            plt.ylim([0, 11])\n",
    "            plt.plot([1,1], [1, 10], c=\"navy\", linewidth=3)\n",
    "            plt.plot([5,5], [1, 10], c=\"navy\", linewidth=3)\n",
    "            plt.plot([1,5], [10, 10], c=\"navy\", linewidth=3)\n",
    "            plt.plot([1,5], [1, 1], c=\"navy\", linewidth=3)\n",
    "            ax.fill_between([1,5], [10,10], [1,1], facecolor='black', alpha=0.05)\n",
    "            ax.set_xlabel('x1', labelpad=10)\n",
    "            ax.set_ylabel('x2', labelpad=10)\n",
    "            plt.savefig('Saved_figures/MLIO2Dfig' + str(k) +'.png')\n",
    "            plt.show()\n",
    "            \n",
    "    return dif_train_base, centers_new, opt_gap_emb, data, dif_test, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find cluster function from points in clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster_from_observations(X, X_train):\n",
    "    m = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    X_test = np.zeros ([m+1,k])\n",
    "    X_test[0:m]= X\n",
    "    X_testT = X_test.T\n",
    "    X_trainT = X_train.T\n",
    "    temp = np.array([])\n",
    "    iteration = 0\n",
    "    for i in range(X_testT.shape[0]):\n",
    "        for j in np.unique(X_train.T[:,m]):\n",
    "            dist = 0\n",
    "            count = 0\n",
    "            for n in range(X_train.T.shape[0]):\n",
    "                if X_trainT[n,m] == j:\n",
    "                    #dist += np.linalg.norm(X_testT[i,0:m] - X_trainT[n,0:m]) \n",
    "                    dist += sum (abs (X_testT[i,0:m] - X_trainT[n,0:m]))\n",
    "                    count += 1\n",
    "            dist = dist / count\n",
    "            if iteration == 0: \n",
    "                dist_min = dist\n",
    "                iteration +=1\n",
    "                X_test[m,i] = j\n",
    "            elif dist < dist_min: \n",
    "                dist_min = dist\n",
    "                X_test[m,i] = j\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find cluster function 2 (from centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster_from_center(X, labels, centers):\n",
    "    m = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    X_test = np.zeros ([m+1,k])\n",
    "    X_test[0:m]= X\n",
    "    X_testT = X_test.T\n",
    "    for i in range (m):\n",
    "        for label in range(labels.shape[0]):\n",
    "            if label == 0:\n",
    "                dist_min = sum (abs (X[i,:] - centers[label,:]))\n",
    "                label_min = label\n",
    "            else: \n",
    "                dist = sum (abs (X[i,:] - centers[label,:]))\n",
    "                if dist <= dist_min: \n",
    "                    dist_min = dist\n",
    "                    label_min = label\n",
    "        X_test[i,m]= labels[label_min]\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draw 2D figure function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bar graph result function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster_from_center(*argv):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    s = 50\n",
    "    for arg in argv:\n",
    "        plt.bar (np.arange(1, arg.shape[0]+ 1), arg[:arg.shape[0]], width = 0.2)#, c=\"navy\")\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Total Distances')\n",
    "    plt.title('Comparison of the sum of Loss Functions with Different Models')\n",
    "    plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
